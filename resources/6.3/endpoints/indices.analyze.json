{
    "__import_file": ["_analysis"],
        "type": {
            "__as_type":"string",
            "__children_of": "token_filters"
        },
        "text": {
            "__as_type": ["array", "string"]
        },
        "analyzer": {
            "__as_type":"string",
            "__children_of": "analyzers"
        },
        "tokenizer": {
            "__as_type":"string",
            "__children_of": "tokenizers"
        },
        "filter": [{
            "type": {
                "__as_type":"string",
                "__children_of": "token_filters"
            }
        }],
        "char_filter": [""],
        "normalizer": {
            "__as_type":"string",
            "__children_of": "normalization_token_filters"
        }
}